#!/usr/bin/env python3
"""
Converts transcripts.json into a TypeScript data file
that can be used as context for the Gemini system prompt.
"""

import json
import os


def main():
    with open("scripts/transcripts.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    # Deduplicate by title, keep only videos with substantial content
    seen_titles = set()
    unique_videos = []
    for v in data["videos"]:
        if v["title"] not in seen_titles and v["wordCount"] > 50:
            seen_titles.add(v["title"])
            unique_videos.append(v)

    # Build the context string for system prompt
    context_parts = []
    context_parts.append("=== AgeSA ile Finansal Terapi - YouTube Video İçerikleri ===")
    context_parts.append(f"Toplam {len(unique_videos)} video\n")

    for i, video in enumerate(unique_videos, 1):
        context_parts.append(f"--- VIDEO {i}: {video['title']} ---")
        context_parts.append(f"URL: {video['url']}")
        context_parts.append(f"İçerik:")
        
        # Use segments with timestamps for better referencing
        for seg in video["segments"]:
            context_parts.append(f"[{seg['timestamp']}] {seg['text']}")
        
        context_parts.append("")  # blank line between videos

    context_text = "\n".join(context_parts)

    # Generate TypeScript file
    # Escape backticks and ${} in the text for template literal safety
    escaped_text = context_text.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")

    video_index = [
        {
            "title": v["title"],
            "url": v["url"],
            "videoId": v["videoId"],
            "wordCount": v["wordCount"],
        }
        for v in unique_videos
    ]
    video_index_json = json.dumps(video_index, ensure_ascii=False, indent=2)
    total_words = sum(v["wordCount"] for v in unique_videos)

    ts_content = f'''// Auto-generated from YouTube playlist transcripts
// Playlist: AgeSA ile Finansal Terapi
// URL: {data["playlist"]["url"]}
// Videos: {len(unique_videos)}
// Total words: {total_words}
// Generated by: scripts/generate_transcript_data.py

export const TRANSCRIPT_CONTEXT = `{escaped_text}`;

export const VIDEO_INDEX = {video_index_json};
'''

    output_path = "src/data/transcripts.ts"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(ts_content)

    print(f"Generated {output_path}")
    print(f"  Videos: {len(unique_videos)}")
    print(f"  Words: {sum(v['wordCount'] for v in unique_videos)}")
    print(f"  File size: {os.path.getsize(output_path) / 1024:.1f} KB")


if __name__ == "__main__":
    main()
